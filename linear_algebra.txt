Algebra: Constructing set of objects and a set of rules to manipulate those objects, to formalize intuitive concepts.

Linear Algebra: Study of vectors and certain rules to manipulate those vectors.

In general, vectors are special objects that can be added together and multiplied by scalars to produce another object of the same kind.

From abstract mathematical viewpoint, any object that satisfies these two properties can be considered a vector.

One major idea in mathematics is the idea of "closure". What is the set of all things that can result from my proposed operations?

In the case of vectors, the question would be: What is the set of vectors that can result by starting with small set of vectors and adding them to each other and scaling them?

This results in vector space. The concept of vector space and its properties underlie much of machine learning.

Systems of Linear Equations:
Many problems can be formulated as systems of linear equations, and linear algebra gives us the tools for solving them.

In general, for a real-valued system of linear equations we obtain a either no, exactly one, or infinitely many solutions.

For a systematic approach to solving systems of linear equations, we will introduce a useful compact notation. We collect the coefficients aij into vectors and collect the vectors into matrices.

Matrices:
They can be used to compactly represent systems of linear equations, but they also represent linear functions (linear mappings).

Matrix operations:
Addition and Multiplication:
Addition is element wise, Multiplication is dot product of rows and columns. Element wise multiplication is known as hadamard product.
Associative, Distributive

Inverse and Transpose:
Inverse: A square matrix A belongs to R. Let matrix B also belongs to R have the property that AB = I = BA. B is called the inverse of A and is denoted by A^-1.
Not every matrix A posses an inverse A^-1. If inverse does exist, A is called regular/ invertible/ nonsingular, otherwise singular/ noninvertible.
When the matrix inverse exists, it is unique.

Transpose: For A belongs to R(m x n) the matrix B belongs to R(n x m) with bij = aji is called the transpose of A. We write B = A^t.

Symmetric Matrix: A matrix A belongs to R(n x n) is symmetric if A = A^t.
The sum of two symmetric matrices is always symmetric.

Multiplication by a Scalar:
If we have a scalar lambda belongs to R and a matrix A belongs to R(m x n). Then lambdaA = K, kij = lambdaaij.
Practically lambda scales each element of A.

Compact Representations of Systems of Linear Equations:
Generally, a system of linear equations can be compactly represented in the matrix form as Ax = b.

Elementary Transformations:
Key to solving a system of linear equations are elementary transformations that keep the solution set the same, but transform the equation system into a simpler form:
Exchange of two equations (rows in the matrix representing the system of equations).
Multiplication of an equation (row) with a constant.
Addition of two equations (rows).

Row-Echelon Form:
A matrix is in row-echelon form if:
All rows that contain only zeros are at the bottom of the matrix; correspondingly, all rows that contain at least one nonzero element are on top of rows that contain only zeros.
Looking at nonzero rows only, the first nonzero number from the left (also called the pivot or the leading coefficient) is always strictly to right of the pivot or the row above it.

Basic and Free Variables:
The variables correspoding to the pivots in the row-echelon form are called basic variables and the other variables are free variables.

Gaussian elimination:
Gaussian elimination is an algorithm that performs elementary transformations to bring a system of linear equations into reduced row-echelon form.

Vector Spaces:
A Vector Space is a structured space in which vectors live.

Groups:
A group is a set of elements and an operation defined on these elements that keeps some structure of the set intact.
Groups hold closure, associativity, neutral element and inverse element properties.

Abelian Group:
If x, y belongs to a set g, then, x (operation) y = y (operation) x, then G = (g, operation) is an Abelian group (commutative).

More about vector space:
A real valued vector space V = (v, vector operation, scalar operation)
(v, +) is an Abelian group.
The elements x belongs V are called vectors.
There is no such thing as vector multiplication, it is not defined.
Closure property guarantees that we end up with another vector in the same vector space when vector addition or scalar multiplication is done.

Vector Subspace: just the subset of vector space set.

Basis: It is possible to find a set of vectors with which we can represent every vector in the vector space by adding them together and scaling them. This set of vectors is called a basis.
Linear Combination: Consider a vector space V and a finite number of vectors x1, x2 ...xk belongs to V. Then every vector which belongs to V is of the form lambda1 x1 + lambda2 x2 ... lambdak xk, with lambda1, lambda2 is a linear combination of the vectors x1, x2 ...xk

Linear Dependence: If there is a non-trivial combination, such that 0 = lambda1 x1 + lambda2 x2 ... lambdak xk with atleast one lambda i != 0, the vectors are linearly dependent. They form basis for the vector space.
Linear Independence: If a trivial solution exists, such that lambda 1 = lambda 2 ... = 0. then the vectors are linearly independent. The vector space does not have a basis.

